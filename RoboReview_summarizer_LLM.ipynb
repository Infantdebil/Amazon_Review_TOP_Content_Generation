{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Product Review Summary\n",
    "\n",
    "Generative AI Summaries: Use Large Language Models (LLMs) to summarize reviews and generate articles recommending the top products in each category. Classical summarization techniques are intentionally avoided for this task to leverage the power of state-of-the-art LLMs.\n",
    "\n",
    "\n",
    "Create a model which, for each product category, generates a short article, like a blogpost reviewer would write, to help customers choose the best one for them.\n",
    "Here’s a suggestion of what the model may output\n",
    "The Top 3 products and key differences between them. When should a consumer choose one or another?\n",
    "Top complaints for each of those products\n",
    "What is the worst product in the category and why you should never buy it\n",
    "More ideas: Look at the Consumer Reviews website, The Verge, The Wirecutter…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup & Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cohere in /opt/anaconda3/lib/python3.12/site-packages (5.13.6)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /opt/anaconda3/lib/python3.12/site-packages (from cohere) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /opt/anaconda3/lib/python3.12/site-packages (from cohere) (0.27.0)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from cohere) (0.4.0)\n",
      "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from cohere) (0.9.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /opt/anaconda3/lib/python3.12/site-packages (from cohere) (2.8.2)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /opt/anaconda3/lib/python3.12/site-packages (from cohere) (2.20.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from cohere) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /opt/anaconda3/lib/python3.12/site-packages (from cohere) (0.21.0)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from cohere) (2.32.0.20241016)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from cohere) (4.12.2)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.21.2->cohere) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.21.2->cohere) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.21.2->cohere) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.21.2->cohere) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=1.9.2->cohere) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/anaconda3/lib/python3.12/site-packages (from tokenizers<1,>=0.15->cohere) (0.26.5)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install cohere\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import nltk\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import cohere\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the pre-processed Data \n",
    "\n",
    "Processed and Sentiment added and clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataset_with_ sentiment_clustered.csv'  # loading file from directory \n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>rating_sentiment_match</th>\n",
       "      <th>name_and_category</th>\n",
       "      <th>categories_clean</th>\n",
       "      <th>category_cluster</th>\n",
       "      <th>cluster_name</th>\n",
       "      <th>mismatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>Kindle</td>\n",
       "      <td>Kindle This product so far has not disappointe...</td>\n",
       "      <td>kindle product far disappointed children love ...</td>\n",
       "      <td>['kindle', 'product', 'far', 'disappointed', '...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>all-new fire hd 8 tablet, 8 hd display, wi-fi,...</td>\n",
       "      <td>fire tablet tablets tablets fire tablets table...</td>\n",
       "      <td>0</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>very fast</td>\n",
       "      <td>very fast great for beginner or experienced pe...</td>\n",
       "      <td>fast great beginner experienced person bought ...</td>\n",
       "      <td>['fast', 'great', 'beginner', 'experienced', '...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>all-new fire hd 8 tablet, 8 hd display, wi-fi,...</td>\n",
       "      <td>fire tablet tablets tablets fire tablets table...</td>\n",
       "      <td>0</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name   brand  \\\n",
       "0  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  Amazon   \n",
       "1  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  Amazon   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "1  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "\n",
       "               reviews.date  reviews.numHelpful  reviews.rating  \\\n",
       "0  2017-01-13T00:00:00.000Z                 0.0             5.0   \n",
       "1  2017-01-13T00:00:00.000Z                 0.0             5.0   \n",
       "\n",
       "                                        reviews.text reviews.title  \\\n",
       "0  This product so far has not disappointed. My c...        Kindle   \n",
       "1  great for beginner or experienced person. Boug...     very fast   \n",
       "\n",
       "                                       combined_text  \\\n",
       "0  Kindle This product so far has not disappointe...   \n",
       "1  very fast great for beginner or experienced pe...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  kindle product far disappointed children love ...   \n",
       "1  fast great beginner experienced person bought ...   \n",
       "\n",
       "                                      tokenized_text  sentiment  \\\n",
       "0  ['kindle', 'product', 'far', 'disappointed', '...          5   \n",
       "1  ['fast', 'great', 'beginner', 'experienced', '...          5   \n",
       "\n",
       "   rating_sentiment_match                                  name_and_category  \\\n",
       "0                    True  all-new fire hd 8 tablet, 8 hd display, wi-fi,...   \n",
       "1                    True  all-new fire hd 8 tablet, 8 hd display, wi-fi,...   \n",
       "\n",
       "                                    categories_clean  category_cluster  \\\n",
       "0  fire tablet tablets tablets fire tablets table...                 0   \n",
       "1  fire tablet tablets tablets fire tablets table...                 0   \n",
       "\n",
       "  cluster_name  mismatch  \n",
       "0       Tablet      True  \n",
       "1       Tablet      True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'brand', 'categories', 'reviews.date', 'reviews.numHelpful',\n",
       "       'reviews.rating', 'reviews.text', 'reviews.title', 'combined_text',\n",
       "       'cleaned_text', 'tokenized_text', 'sentiment', 'rating_sentiment_match',\n",
       "       'name_and_category', 'categories_clean', 'category_cluster',\n",
       "       'cluster_name', 'mismatch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fix: Convert the 'reviews.date' column to datetime\n",
    "data['reviews.date'] = pd.to_datetime(data['reviews.date'], errors='coerce')  # Convert and handle invalid dates\n",
    "\n",
    "# Step 1: Define helper functions\n",
    "def combine_reviews_by_sentiment(df, sentiment_range, max_reviews=10):\n",
    "    \"\"\"\n",
    "    Combine up to `max_reviews` (title + text) for a specific sentiment range.\n",
    "    \"\"\"\n",
    "    filtered_reviews = df[(df['sentiment'] >= sentiment_range[0]) & (df['sentiment'] <= sentiment_range[1])]\n",
    "    filtered_reviews = filtered_reviews.head(max_reviews)  # Limit to top `max_reviews`\n",
    "    combined_reviews = filtered_reviews['reviews.title'].fillna('') + \" \" + filtered_reviews['reviews.text'].fillna('')\n",
    "    return \" \".join(combined_reviews)\n",
    "\n",
    "def extract_top_keywords(text, n=5):\n",
    "    \"\"\"\n",
    "    Extract the top `n` keywords from the text using CountVectorizer.\n",
    "    \"\"\"\n",
    "    if not text.strip():  # Check if the text is empty or contains only whitespace\n",
    "        return \"\"\n",
    "    vectorizer = CountVectorizer(max_features=n, stop_words='english')\n",
    "    X = vectorizer.fit_transform([text])\n",
    "    return \", \".join(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Step 2: Group data by product and calculate metrics\n",
    "grouped_data = data.groupby(['name', 'category_cluster', 'cluster_name']).agg(\n",
    "    mean_sentiment=('sentiment', 'mean'),  # Calculate the mean sentiment\n",
    "    review_count=('reviews.text', 'count'),  # Count the number of reviews\n",
    "    pro_reviews_count=('sentiment', lambda x: sum((x >= 4) & (x <= 5))),  # Count reviews with sentiment 4-5\n",
    "    con_reviews_count=('sentiment', lambda x: sum((x >= 1) & (x <= 2))),  # Count reviews with sentiment 1-2\n",
    "    most_recent_review=('reviews.date', 'max')  # Get the date of the most recent review\n",
    ").reset_index()\n",
    "\n",
    "# Step 3: Create combined reviews for pro (4-5 sentiment) and con (1-2 sentiment)\n",
    "grouped_data['product_review_context_combined_pro'] = grouped_data.apply(\n",
    "    lambda row: combine_reviews_by_sentiment(\n",
    "        data[(data['name'] == row['name']) & (data['category_cluster'] == row['category_cluster'])],\n",
    "        sentiment_range=(4, 5),\n",
    "        max_reviews=10  # Limit to 10 reviews\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "grouped_data['product_review_context_combined_con'] = grouped_data.apply(\n",
    "    lambda row: combine_reviews_by_sentiment(\n",
    "        data[(data['name'] == row['name']) & (data['category_cluster'] == row['category_cluster'])],\n",
    "        sentiment_range=(1, 2),\n",
    "        max_reviews=10  # Limit to 10 reviews\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Step 4: Extract top keywords for pro and con reviews\n",
    "grouped_data['pro_keywords'] = grouped_data['product_review_context_combined_pro'].apply(\n",
    "    lambda x: extract_top_keywords(x, n=5)\n",
    ")\n",
    "\n",
    "grouped_data['con_keywords'] = grouped_data['product_review_context_combined_con'].apply(\n",
    "    lambda x: extract_top_keywords(x, n=5)\n",
    ")\n",
    "\n",
    "# Step 5: Calculate ranking for products with more than 100 reviews\n",
    "grouped_data['top_product_ranking'] = (\n",
    "    grouped_data[grouped_data['review_count'] > 100]\n",
    "    .groupby('category_cluster')['mean_sentiment']\n",
    "    .rank(ascending=False, method='dense')\n",
    ")\n",
    "\n",
    "# Step 6: Sort the data\n",
    "sorted_data = grouped_data.sort_values(\n",
    "    by=['category_cluster', 'top_product_ranking'],\n",
    "    ascending=[True, True]\n",
    ")\n",
    "\n",
    "# Step 7: Select the required columns\n",
    "final_data = sorted_data[\n",
    "    ['cluster_name','category_cluster', 'name', 'mean_sentiment', 'review_count',\n",
    "     'top_product_ranking', 'most_recent_review',\n",
    "     'product_review_context_combined_pro', 'product_review_context_combined_con',\n",
    "     'pro_reviews_count', 'con_reviews_count', 'pro_keywords', 'con_keywords']\n",
    "].rename(columns={'name': 'product_name'})\n",
    "\n",
    "# # Save and Inspect to CSV\n",
    "# output_file = \"product_reviews_enhanced.csv\"\n",
    "# final_data.to_csv(output_file, index=False)\n",
    "\n",
    "# print(f\"CSV file has been saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file if used\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Product_Category', 'Category_name', 'Headline_for_TOP_Product',\n",
       "       'Teaser_text', 'Product_Top_1', 'Product_Top_1_Pro_Sentiment',\n",
       "       'Product_Top_2', 'Product_Top_2_Pro_Sentiment', 'Product_Top_3',\n",
       "       'Product_Top_3_Pro_Sentiment', 'Product_Top_1_Pros',\n",
       "       'Product_Top_1_Cons', 'Positive_Quote', 'Summary_Reviews_High',\n",
       "       'Summary_Reviews_Low', 'Wrapup'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your example CSV Output\n",
    "example_data = pd.read_csv(\"blog_posts_for_website_example.csv\")\n",
    "\n",
    "example_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.rename(columns={'category_cluster': 'Product_Category'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cluster_name', 'Product_Category', 'product_name', 'mean_sentiment',\n",
       "       'review_count', 'top_product_ranking', 'most_recent_review',\n",
       "       'product_review_context_combined_pro',\n",
       "       'product_review_context_combined_con', 'pro_reviews_count',\n",
       "       'con_reviews_count', 'pro_keywords', 'con_keywords'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'blog_posts_for_website.csv' has been generated!\n"
     ]
    }
   ],
   "source": [
    "# changes reordering and all columns / reduce to just top 1 \n",
    "\n",
    "# Load your dataset\n",
    "example_data = pd.read_csv(\"blog_posts_for_website_example.csv\")\n",
    "\n",
    "# Initialize Cohere client\n",
    "co = cohere.Client(COHERE_API_KEY)  # Replace with your Cohere API Key\n",
    "\n",
    "# Define a function to generate content using Cohere\n",
    "def generate_content(prompt):\n",
    "    response = co.generate(\n",
    "        model='command-xlarge-nightly',  # Use Cohere's advanced model\n",
    "        prompt=prompt,\n",
    "        max_tokens=300,  # Adjust token limit based on the column\n",
    "        temperature=0.7,  # For balanced creativity and coherence\n",
    "        stop_sequences=[\"\\n\"]  # Stops generation after the first paragraph\n",
    "    )\n",
    "    return response.generations[0].text.strip()\n",
    "\n",
    "# Define prompt templates for each column\n",
    "def create_prompt_for_column(column_name, row, example):\n",
    "    \"\"\"\n",
    "    Create a prompt for generating specific columns.\n",
    "    :param column_name: The column to generate content for.\n",
    "    :param row: The row from the dataset.\n",
    "    :param example: An example row from the blog_posts_for_website_example.csv.\n",
    "    :return: A string prompt.\n",
    "    \"\"\"\n",
    "    # Handle missing data for review contexts\n",
    "    positive_reviews = row['product_review_context_combined_pro'][:500] if row.get('product_review_context_combined_pro') else \"No positive reviews available.\"\n",
    "    negative_reviews = row['product_review_context_combined_con'][:500] if row.get('product_review_context_combined_con') else \"No negative reviews available.\"\n",
    "\n",
    "    if column_name == \"Headline_for_TOP_Product\":\n",
    "        return f\"\"\"Here is an example headline for a top product:\n",
    "        Product Name: {example['Product_Top_1']}\n",
    "        Example Headline: {example['Headline_for_TOP_Product']}\n",
    "        \n",
    "        Now, create a headline for this product:\n",
    "        Product Name: {row['product_name']}\n",
    "        Category: {row['Product_Category']}\n",
    "        Positive Sentiment: {row['pro_reviews_count']}\n",
    "        Headline:\"\"\"\n",
    "\n",
    "    if column_name == \"Teaser_text\":\n",
    "        return f\"\"\"Here is an example teaser text for a product:\n",
    "        Product Name: {example['Product_Top_1']}\n",
    "        Example Teaser: {example['Teaser_text']}\n",
    "        \n",
    "        Now, create a teaser text for this product:\n",
    "        Product Name: {row['product_name']}\n",
    "        Category: {row['Product_Category']}\n",
    "        Combined Reviews (Positive): {positive_reviews}\n",
    "        Teaser:\"\"\"\n",
    "\n",
    "    if column_name == \"Product_Top_1_Pros\":\n",
    "        return f\"\"\"Here is an example summary of pros for a product:\n",
    "        Product Name: {example['Product_Top_1']}\n",
    "        Example Pros: {example['Product_Top_1_Pros']}\n",
    "        \n",
    "        Now, summarize the pros for this product based on customer reviews:\n",
    "        Product Name: {row['product_name']}\n",
    "        Positive Reviews: {positive_reviews}\n",
    "        Based on customer reviews, list 2-3 positive technical bullet points of this product (each bullet point max 3 words). Focus on specific features and performance benefits mentioned by users. Write concise and professional bullet points:\n",
    "        Pros:\"\"\"\n",
    "\n",
    "    if column_name == \"Product_Top_1_Cons\":\n",
    "        return f\"\"\"Here is an example summary of cons for a product:\n",
    "        Product Name: {example['Product_Top_1']}\n",
    "        Example Cons: {example['Product_Top_1_Cons']}\n",
    "        \n",
    "        Now, summarize the cons for this product based on customer reviews:\n",
    "        Negative Reviews: {negative_reviews}\n",
    "        Based on customer reviews, list 2-3 positive technical bullet points of this product (each bullet point max 3 words). Focus on specific features and performance concerns mentioned by users. Write concise and professional bullet points:\n",
    "\n",
    "        Cons:\"\"\"\n",
    "\n",
    "    if column_name == \"Summary_Reviews_High\":\n",
    "        return f\"\"\"Here is an example summary of high reviews for a category:\n",
    "        Category: {example['Product_Category']}\n",
    "        Example Summary: {example['Summary_Reviews_High']}\n",
    "        \n",
    "        Now, summarize all high reviews for this category:\n",
    "        Positive Reviews for All Products: {positive_reviews}\n",
    "        Write a concise, professional summary (2-3 sentences) focusing on the main benefits and user feedback:\n",
    "        No Category number or naming. \n",
    "        Summary:\"\"\"\n",
    "\n",
    "    if column_name == \"Summary_Reviews_Low\":\n",
    "        return f\"\"\"Here is an example summary of low reviews for a category:\n",
    "        Category: {example['Product_Category']}\n",
    "        Example Summary: {example['Summary_Reviews_Low']}\n",
    "        \n",
    "        Now, summarize all low reviews for this category:\n",
    "        Negative Reviews for All Products: {negative_reviews}\n",
    "        Write a concise, professional summary (2-3 sentences) focusing on the main issues and concerns raised by users:\n",
    "        No Category number or naming. \n",
    "        Summary:\"\"\"\n",
    "\n",
    "    if column_name == \"Wrapup\":\n",
    "        return f\"\"\"Here is an example wrap-up for a category:\n",
    "        Category: {example['Product_Category']}\n",
    "        Example Wrapup: {example['Wrapup']}\n",
    "        \n",
    "        Now, write a wrap-up for this category:\n",
    "        Highlights: {positive_reviews}\n",
    "        Concerns: {negative_reviews}\n",
    "        Write a professional wrap-up in 2-3 sentences that provides a balanced overview:\n",
    "        No Category number or naming. \n",
    "        Wrapup:\"\"\"\n",
    "\n",
    "# Filter and rank products within each category\n",
    "final_data[\"rank\"] = final_data.groupby(\"Product_Category\")[\"top_product_ranking\"].rank(ascending=False)\n",
    "top_3_data = final_data[final_data[\"rank\"] <= 3]  # Filter Top 3 products\n",
    "top_product_data = top_3_data[top_3_data[\"rank\"] == 1]  # Filter only the top-ranked product for certain fields\n",
    "\n",
    "\n",
    "# Prepare the output DataFrame\n",
    "output_columns = [\n",
    "    \"Product_Category\", \"Category_name\", \n",
    "    \"Headline_for_TOP_Product\", \"Teaser_text\",\n",
    "    \"Product_Top_1\", \"Product_Top_1_Pro_Sentiment\",\n",
    "    \"Product_Top_2\", \"Product_Top_2_Pro_Sentiment\",\n",
    "     \"Product_Top_3\", \"Product_Top_3_Pro_Sentiment\",\n",
    "     \"Product_Top_1_Pros\", \"Product_Top_1_Cons\",\n",
    "     \"Positive Quote\", \"Summary_Reviews_High\", \"Summary_Reviews_Low\", \n",
    "     \"Wrapup\"\n",
    "]\n",
    "output_data = []\n",
    "\n",
    "# Iterate over the categories and combine Top 1, Top 2, and Top 3 into one row per category\n",
    "categories = final_data[\"Product_Category\"].unique()\n",
    "\n",
    "for category in categories:\n",
    "    category_data = final_data[final_data[\"Product_Category\"] == category]  \n",
    "    # Sort products by `top_product_ranking` (lower is better)\n",
    "    category_data = category_data.sort_values(by=\"top_product_ranking\")\n",
    "\n",
    "    # Extract the top products\n",
    "    product_top_1 = category_data.iloc[0]\n",
    "    product_top_2 = category_data.iloc[1] if len(category_data) > 1 else None\n",
    "    product_top_3 = category_data.iloc[2] if len(category_data) > 2 else None\n",
    "\n",
    "    # Create a single row with all top products for the category\n",
    "    row_output = {\n",
    "        \"Product_Category\": product_top_1[\"Product_Category\"],\n",
    "        \"Category_name\": product_top_1[\"cluster_name\"],\n",
    "        \"Headline_for_TOP_Product\": generate_content(create_prompt_for_column(\"Headline_for_TOP_Product\", product_top_1, example_data.iloc[0])),\n",
    "        \"Teaser_text\": generate_content(create_prompt_for_column(\"Teaser_text\", product_top_1, example_data.iloc[0])),\n",
    "        \"Product_Top_1\": product_top_1[\"product_name\"],\n",
    "        \"Product_Top_1_Pro_Sentiment\": round(product_top_1[\"mean_sentiment\"], 2),\n",
    "        \"Product_Top_1_Pros\": generate_content(create_prompt_for_column(\"Product_Top_1_Pros\", product_top_1, example_data.iloc[0])),\n",
    "        \"Product_Top_1_Cons\": generate_content(create_prompt_for_column(\"Product_Top_1_Cons\", product_top_1, example_data.iloc[0])),\n",
    "        \"Product_Top_2\": product_top_2[\"product_name\"] if product_top_2 is not None else None,\n",
    "        \"Product_Top_2_Pro_Sentiment\": round(product_top_2[\"mean_sentiment\"], 2) if product_top_2 is not None else None,\n",
    "        \"Product_Top_3\": product_top_3[\"product_name\"] if product_top_3 is not None else None,\n",
    "        \"Product_Top_3_Pro_Sentiment\": round(product_top_3[\"mean_sentiment\"], 2) if product_top_3 is not None else None,\n",
    "        \"Positive Quote\": product_top_1[\"product_review_context_combined_pro\"].split(\".\")[0] if product_top_1[\"product_review_context_combined_pro\"] else \"No positive quote available.\",\n",
    "        \"Summary_Reviews_High\": generate_content(create_prompt_for_column(\"Summary_Reviews_High\", product_top_1, example_data.iloc[0])),\n",
    "        \"Summary_Reviews_Low\": generate_content(create_prompt_for_column(\"Summary_Reviews_Low\", product_top_1, example_data.iloc[0])),\n",
    "        \"Wrapup\": generate_content(create_prompt_for_column(\"Wrapup\", product_top_1, example_data.iloc[0])),\n",
    "    }\n",
    "\n",
    "    output_data.append(row_output)\n",
    "\n",
    "\n",
    "# Convert the output to a DataFrame and save as CSV\n",
    "output_df = pd.DataFrame(output_data, columns=output_columns)\n",
    "output_df.to_csv(\"blog_posts_for_website.csv\", index=False)\n",
    "\n",
    "print(\"File 'blog_posts_for_website.csv' has been generated!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
